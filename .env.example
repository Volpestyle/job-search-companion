# LLM Provider Configuration
# Options: ollama, openai, anthropic
LLM_PROVIDER=ollama

# Ollama Configuration
OLLAMA_HOST=localhost
OLLAMA_PORT=11434
OLLAMA_MODEL=qwen2.5:32b
# Dummy API key for Ollama (required by Stagehand but not actually used)
OLLAMA_API_KEY=ollama

# OpenAI Configuration (if using OpenAI)
# OPENAI_API_KEY=your-openai-api-key
# OPENAI_MODEL=gpt-4-turbo-preview

# Anthropic Configuration (if using Anthropic)
# ANTHROPIC_API_KEY=your-anthropic-api-key
# ANTHROPIC_MODEL=claude-3-opus-20240229

# Stagehand Environment
# Options: LOCAL, AWS
STAGEHAND_ENV=LOCAL

# AWS Configuration (if using AWS browser)
# AWS_CDP_ENDPOINT=ws://your-aws-instance:9222/devtools/browser/xyz
# AWS_REGION=us-east-1
# AWS_INSTANCE_ID=i-1234567890abcdef0